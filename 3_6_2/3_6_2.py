# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vv_qcp1HQH-iwv_eBnN9uFQXm76a3Zfd
"""

#pip install pyspark

import random
from datetime import datetime as dt
from datetime import timedelta
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType, FloatType

spark = SparkSession.builder \
    .appName("orders") \
    .getOrCreate()
schema = StructType([
    StructField("Дата", DateType(), True),
    StructField("UserID", StringType(), True),
    StructField("Продукт", StringType(), True),
    StructField("Количество", IntegerType(), True),
    StructField("Цена", FloatType(), True)
])

start_dt = dt.strptime('01.01.2024', '%d.%m.%Y')
end_dt = dt.strptime('10.10.2024', '%d.%m.%Y')

data =[((start_dt + timedelta(random.randint(0, (end_dt-start_dt).days))),
       f'user{random.randint(10,100)}',
       random.choice(['banana','apple','kiwi','cucumber','potato']),
       random.randint(1,10),
       round(random.uniform(50,120),2)) for i in range(1000)]
orders = spark.createDataFrame(data, schema)

orders.repartition(1).write.format('com.databricks.spark.csv').save("orders.csv",header = 'true')

spark.stop()